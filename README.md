



# Îµiko

**Îµiko** stands for "**Îµ**iko : **i**nterop **k**nowledge **o**perations". 
 **Îµiko** is aims to be a standardized solution for deploying and operationalizing data science tools with advanced DevOps practices.

## About the project

### What's Included

**Development Environment**
- Makefile, README, Docker, requirements.txt, classes for data manipulation and computation

**Production Backend**
- FastAPI with pagination and authentication
- Pytest testing suite
- CLI interface via Click framework

### Multi-Perspective Solution
As a **Key Benefit**, **Îµiko**  focus on data science while ensuring enterprise-grade deployment standards :

- **For Developers:** A framework and top layer for manipulating data libraries within a built-in environment. Or just a project template or a code skeleton, if *you wanna do a proper job*.

- **For Users:** A data and service provider accessible through APIs.

- **For Project Leaders:** A platform that ensures delivery and practice quality.

### Business Focus: Environmental Value

Eiko specializes in complex spatial data operations, enabling:
- Cross-referencing of administrative and ecological scientific data
- Output generation: data visualizations, statistical analyses, and sophisticated models
- Satellite image processing and automated model rendering via PRISME library integration


### Core concept: smart integration (*the simpler is the better*)

Eiko doesn't aim to be a code providerâ€”it's intelligent *glue* between powerful existing data tools (Pandas, Scikit-Learn, Seaborn, PyTorch, Pydantic...). Unlike typical projects where tool selection is driven by habits, Eiko prioritizes resource consumption, maintainability, low-cost performance and cost-effectiveness.

Built on principles of **sovereignty**, **ease-of-use**, and **maintainability** with a focus on **sobriety**. We prioritize the lightest and simplest solutions.

Fork it, copy it, use parts or all functionalities. The main objective is providing data users and developers a common foundation to initiate projects and start creating value as early as possible. That's doesn't mean using the "lowest-level" or "the most powerfull" code, just testing and using the lightest and more reliable one, for the job to be done.



### Achievements
#### Key Performance Indicators (KPI) describers :

Feature readiness assessment for...

##### ğŸƒ ... Digital frugality
**"Don't do it at too high a cost."**  
Emphasizes efficiency and minimalism. Has the feature been validated on representative datasets? Are there consumption metrics available for the libraries used?

##### ğŸŒ±... Environmental potential
**"Don't do it if it's useless."**  
Encompasses digital sobriety (reducing digital resource consumption and environmental impact through mindful technology use) and empowering users to adopt sustainable coding practices and integrate environmental considerations into decision-making processes. Also indicates the solution's coverage scope within the field of interest.

##### ğŸš¦... Use readiness
**"Don't do it if you're not ready."**  
Indicates that the solution is immediately deployable for business purposes without requiring additional development, training, technical/infrastructure modifications, or financial investment. This KPI considers also technical interoperability and adaptation to new trends.

##### ğŸš€... Deployment abilities
**"Don't do it if you can't use it."**  
"Is the solution mature? Are the underlying libraries battle-tested across thousands of projects over years? Should we anticipate deployment, implementation, or integration challenges? Have the chosen software components proven their reliability?

##### â²... Overall performances
**"Don't do it if it doesn't work."**  
Assesses the solution's technical performance and value proposition. From a purely technical standpoint, does it deliver worthwhile benefits through the licecycle evaluation (development, production, and service delivery)? Consider that while some projects may initially be profitable, increasing complexity can eventually lead to project failure.

##### ğŸ‘¥... Communities engagement and maintenance
**"Don't do it alone."**  
Open source projects are only valuable when their core components and dependencies receive active community contributions. Projects require active communities and maintained source code. Any project without commits in the last six months should be critically evaluated during major reviews.

##### ğŸ“... Analytic capacities
**"Don't do it, if you don't know how it works."**  
Evaluates the ability to integrate domain-specific libraries and assesses the quality and reliability of data modeling, data quality, and analytical tools. Prioritizes foundational features like clear sorting mechanisms, comprehensible statistics, and well-documented, established criteria.


##### ğŸ”¬... Scientific capacities
**"Don't do it without insights."**  
This KPI doesn't measure the connection between scholar domains and the solutionâ€”it evaluates the tool's capacity to integrate new models, datasets, and concepts from the environmental sector. These new features are validated through scientific and technical documentation and bibliographic references. Given maintenance costs, this criterion also questions the contribution of built-in methods in the practical use of the tool.

##### â˜£ï¸... Building and project hazards
**"There are other reasons not to do it. But you'll do it anyway."**  
Digital solution development and integration involves distinct challenges. Additional factors are assessed here, along with comprehensive risk analysis.


#### Key Performance Indicators (KPI) levels :
**Levels** :   
- **0** (not implemented), 
- **1** (planned), 
- **2** (basic implementation), 
- **3** (advanced: results based on criterion analysis), 
- **4** (comprehensive: analysis results available and reviewable), 
- **5**(mature: regularly updated analysis used for consensus building)


#### KPIs â€“ Group 1: functional capabilities

***last version reviewed : 0.1***

|  KPI | ğŸƒ  | ğŸŒ±  |  ğŸš¦ |  ğŸš€ | â²  |  ğŸ‘¥ |  ğŸ“ |  ğŸ”¬ |  â˜£ï¸ |
|---|---|---|---|---|---|---|---|---|---|
|Deploy API |  2 |  2 | 2  | 2  |  2 |  2 | 2  | 2  | 2  |   
|Secure API   |  1 |  1 | 1  | 1  |  1 |  1 | 1  | 1  | 1  |   
|API Ergonomy|  2 |  2 | 2  | 2  |  2 |  2 | 2  | 2  | 2  |   

#### KPIs â€“ Group 2: technical enhancements
|  KPI | ğŸƒ  | ğŸŒ±  |  ğŸš¦ |  ğŸš€ | â²  |  ğŸ‘¥ |  ğŸ“ |  ğŸ”¬ |  â˜£ï¸ |
|---|---|---|---|---|---|---|---|---|---|
|Deploy API |  2 |  2 | 2  | 2  |  2 |  2 | 2  | 2  | 2  |   
|Secure API   |  1 |  1 | 1  | 1  |  1 |  1 | 1  | 1  | 1  |   
|API Ergonomy|  2 |  2 | 2  | 2  |  2 |  2 | 2  | 2  | 2  |   

#### KPIs â€“ Group 3: system usage and user experience
|  KPI | ğŸƒ  | ğŸŒ±  |  ğŸš¦ |  ğŸš€ | â²  |  ğŸ‘¥ |  ğŸ“ |  ğŸ”¬ |  â˜£ï¸ |
|---|---|---|---|---|---|---|---|---|---|
|Deploy API |  2 |  2 | 2  | 2  |  2 |  2 | 2  | 2  | 2  |   
|Secure API   |  1 |  1 | 1  | 1  |  1 |  1 | 1  | 1  | 1  |   
|API Ergonomy|  2 |  2 | 2  | 2  |  2 |  2 | 2  | 2  | 2  |   

#### KPIs â€“ Group 4: business metrics
|  KPI | ğŸƒ  | ğŸŒ±  |  ğŸš¦ |  ğŸš€ | â²  |  ğŸ‘¥ |  ğŸ“ |  ğŸ”¬ |  â˜£ï¸ |
|---|---|---|---|---|---|---|---|---|---|
|Deploy API |  2 |  2 | 2  | 2  |  2 |  2 | 2  | 2  | 2  |   
|Secure API   |  1 |  1 | 1  | 1  |  1 |  1 | 1  | 1  | 1  |   
|API Ergonomy|  2 |  2 | 2  | 2  |  2 |  2 | 2  | 2  | 2  |   


## 101 : how to use it

### Install
Create a virtual Python3 environment and activate it.
Go through the requirements file.

#### On MS Windows platform :
```ps1
python -m venv ./venv
/.venv/Scripts/activate.bat
```
Or just use [Ctrl] + [Shift] + [P] for VSCode users.

Then :
```ps1
python -m pip install -r requirements.txt
```

#### On UNIX systems :
```bash
python -m venv ./venv
source venv/bin/activate
pip install -r requirements.txt
```

#### For MAKE users

Installation :

```bash
python -m venv ./venv
source venv/bin/activate
make install
```

Full test :
```bash
make test
```

#### How to test

Everything :

```bash
pytest tests
```

Only a part :

```bash
# Will test only : GisSerie
pytest tests/test_gisserie.py 
# Will test only : Grid
pytest tests/test_grid.py 
# Will test only : Reference
pytest tests/test_reference.py 
# Will test only : ModelOutput
pytest tests/test_modeloutput.py 
# Will test only : Weighter
pytest tests/test_weighter.py 
# Will test only : AlphanumSerie
pytest tests/test_anserie.py
```